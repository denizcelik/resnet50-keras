{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Importing Required Modules & Root Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.layers as tfl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = \"full/path/to/root/folder/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Importing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1- Getting Filenames Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Defining dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = path_root + \"datasets/mydataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Creating list dataset that contains file names with full path by using dataset root path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataset = tf.data.Dataset.list_files(str(path_dataset+\"/*/*\"), shuffle=True)\n",
    "\n",
    "# Examples\n",
    "for ex in list_dataset.take(5):\n",
    "    # Print modified-for-readiblity version of samples \n",
    "    print(ex.numpy().split(b\"/\")[-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2- Getting Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Mapping \"convert path to image\" operation in order to get image dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_path_to_image(name_path):\n",
    "\n",
    "    # Path-to-image conversion and image decoding\n",
    "    path_parts = tf.strings.split(name_path, os.sep)\n",
    "    # Get label from root file of image \n",
    "    label = path_parts[-2]\n",
    "    # Read image from given path\n",
    "    image = tf.io.read_file(name_path)\n",
    "    # Decode image as JPEG\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    \n",
    "    # Return image and label\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Applying the mapping to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = list_dataset.map(convert_path_to_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Testing mapping by sampling image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_test(dataset, num=3, one_hot_label=False, classes=None):\n",
    "\n",
    "    # Defining the subplot\n",
    "    fig, axes = plt.subplots(1,num, figsize=(12,6))\n",
    "    print(dataset.element_spec)\n",
    "    \n",
    "    for i, (image,label) in enumerate(dataset.take(num)):\n",
    "        # Showing the  sample image \n",
    "        axes[i].imshow(image)\n",
    "        # one_hot_label condition\n",
    "        if not one_hot_label:\n",
    "            # If the label is not one-hot-encoded\n",
    "            label = label.numpy().decode(\"utf-8\")\n",
    "        else:\n",
    "            # If the label is one-hot-encoded\n",
    "            print(\"One-Hot label:\", label)\n",
    "            label_ind = tf.argmax(label).numpy()\n",
    "            label = classes[label_ind] \n",
    "        # Showing the label as title\n",
    "        axes[i].set_title(label)\n",
    "        \n",
    "    # Showing the plot \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_test(image_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3- Preprocessing Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Loading class names as a list by using \"class_names.csv\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_list = []\n",
    "path_classes_list_file = path_root +\"datasets/mydataset/class_names.csv\"\n",
    "\n",
    "with open(path_classes_list_file, \"r\", ) as my_file:\n",
    "    new_content = csv.reader(my_file)\n",
    "    for row in new_content:\n",
    "        classes_list.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes_list)\n",
    "print(\"number of classes:\", len(classes_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Defining one_hot_encoder function which takes \"image\" and \"label\" of each element and, outputs \"image\" \"one hot encoded label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(image, label, classes):\n",
    "\n",
    "    # Get the boolean match of the label\n",
    "    tensor_classes_bool = tf.constant(classes) == label\n",
    "    # Cast the boolean result as a tf.float32 tensor\n",
    "    label_one_hot = tf.cast(tensor_classes_bool, dtype=tf.float32)\n",
    "\n",
    "    # Return to replace\n",
    "    return (image, label_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Applying the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = image_dataset.map(lambda image,label: one_hot_encoder(image, label, classes_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2- Applying Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Apply resize, cropping, horizontal flipping, brightnes and contrast changing randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_data_augmentation(image, label, seed=(5,0), size=[224, 224, 3], max_delta=0.3, lower=0.3, upper=1.7):\n",
    "\n",
    "    # Get random dimension\n",
    "    random_size = tf.cast(tf.random.uniform([], minval=256, maxval=481, dtype=tf.int32), dtype=tf.float32)\n",
    "    # Apply random resizing to use random cropping\n",
    "    image = tf.image.resize(image, [random_size, random_size])\n",
    "    # Apply random horizontal flip\n",
    "    image = tf.image.stateless_random_flip_left_right(image, seed)\n",
    "    # Apply random cropping to resized image\n",
    "    image = tf.image.stateless_random_crop(image, size, seed)\n",
    "    # Apply random brightness changing\n",
    "    image = tf.image.stateless_random_brightness(image, max_delta, seed)\n",
    "    # Apply random contrast changing\n",
    "    image = tf.image.stateless_random_contrast(image, lower, upper, seed)\n",
    "\n",
    "    # Return image and label\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Defining random number generator wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = tf.random.Generator.from_seed(21, alg='philox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rng_wrapper_for_data_augmentation(image, label, rng_object):\n",
    "\n",
    "    # create new seed by using rng object\n",
    "    current_seed = rng_object.make_seeds(2)[0]\n",
    "    # apply data augmentation to current image with newly created seed\n",
    "    image, label = apply_data_augmentation(image, label, current_seed)\n",
    "\n",
    "    # return augmentation-applied image and label\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Apply the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = image_dataset.map(lambda image,label: rng_wrapper_for_data_augmentation(image, label, rng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3- Scaling Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Definign rescaler function that rescales each image element to between 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescaler(image,label):\n",
    "\n",
    "    # Apply scaling (normalization from statistic convension) to range between 0-1 \n",
    "    image = tfl.Rescaling(scale=1./255) (image)\n",
    "\n",
    "    # Return image and label\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Apply the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = image_dataset.map(rescaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_test(image_dataset, one_hot_label=True, classes=classes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4- Configuring Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Splitting training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_set_ratio, test_set_ratio, val_set_ratio=0):\n",
    "    \n",
    "    # Get the dataset length\n",
    "    len_dataset = len(image_dataset)\n",
    "\n",
    "    # Check if the ratio is correct\n",
    "    if train_set_ratio + val_set_ratio + test_set_ratio != 1:\n",
    "        raise ValueError(\"Incorrect split ratio\")\n",
    "\n",
    "    # Calculate the indices\n",
    "    train_size = int(len_dataset * train_set_ratio)\n",
    "    remaining_size = int(len_dataset - train_size)\n",
    "\n",
    "    # If the val_set is intended\n",
    "    if val_set_ratio != 0:\n",
    "        val_set_ratio_remaining = float(val_set_ratio / (val_set_ratio + test_set_ratio))\n",
    "        #print(\"val_set_ratio_remaining\", val_set_ratio_remaining)\n",
    "        val_size = int(remaining_size *  val_set_ratio_remaining)\n",
    "        val_index = train_size + val_size\n",
    "        test_size = remaining_size - val_size\n",
    "\n",
    "    else:\n",
    "        test_size = remaining_size\n",
    "\n",
    "    # Write the sizes\n",
    "    print(\"train size:\",train_size)\n",
    "    print(\"test size:\", test_size)\n",
    "    if val_set_ratio != 0: \n",
    "        print(\"val size:\", val_size)\n",
    "\n",
    "    # Split the dataset\n",
    "    dataset_train = dataset.take(train_size)\n",
    "    dataset_remaining = dataset.skip(train_size)\n",
    "\n",
    "    if val_set_ratio != 0:\n",
    "        dataset_val = dataset_remaining.take(val_size)\n",
    "        dataset_test = dataset_remaining.skip(val_size)\n",
    "         \n",
    "        return dataset_train, dataset_test, dataset_val\n",
    "        \n",
    "    else:\n",
    "        dataset_test = dataset_remaining\n",
    "        return dataset_train, dataset_remaining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test, dataset_val = split_dataset(image_dataset, 0.8, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Configuring mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.shuffle(buffer_size=1024, reshuffle_each_iteration=True).batch(16, drop_remainder=True)\n",
    "dataset_val = dataset_val.shuffle(buffer_size=1024, reshuffle_each_iteration=True).batch(16, drop_remainder=True)\n",
    "dataset_test = dataset_test.shuffle(buffer_size=1024, reshuffle_each_iteration=True).batch(16, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Defining the ResNet50 \"identity shortcut block\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(block_input, filters, stage=\"n\", block=\"m\"):\n",
    "    \"\"\"\n",
    "    Identity shortcut block implementation with bottleneck design from ResNet-50 architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the block name with stage prefix\n",
    "    block_name = f\"iden_block_{str(stage)}_{str(block)}\"\n",
    "    bn_name = f\"iden_bn_{str(stage)}_{str(block)}\"\n",
    "\n",
    "    # Unpack the filters input\n",
    "    f1, f2, f3 = filters\n",
    "\n",
    "    # Define the destructing step of bottleneck design, apply BatchNorm and ReLU\n",
    "    block_destruct = tfl.Conv2D(filters=f1, kernel_size=(1,1), strides=(1,1), padding=\"valid\", kernel_initializer=\"he_normal\", name=block_name+ \"_d\") (block_input)\n",
    "    block_destruct = tfl.BatchNormalization(name=bn_name+\"_d\") (block_destruct)\n",
    "    block_destruct = tfl.Activation(\"relu\") (block_destruct)\n",
    "\n",
    "    # Define the feature extractor step of bottleneck design, apply BatchNorm and ReLU\n",
    "    block_neck = tfl.Conv2D(filters=f2, kernel_size=(3,3), strides=(1,1),  padding=\"same\", kernel_initializer=\"he_normal\", name=block_name+ \"_n\") (block_destruct)\n",
    "    block_neck = tfl.BatchNormalization(name=bn_name+\"_n\") (block_neck)\n",
    "    block_neck = tfl.Activation(\"relu\") (block_neck)\n",
    "\n",
    "    # Define the restoring step of bottleneck design, apply BatchNorm and ReLU\n",
    "    block_restore = tfl.Conv2D(filters=f3, kernel_size=(1,1), strides=(1,1), padding=\"valid\", kernel_initializer=\"he_normal\", name=block_name+ \"_r\") (block_neck)\n",
    "    block_restore = tfl.BatchNormalization(name=bn_name+\"_r\") (block_restore)\n",
    "    \n",
    "    # Define shortcut connection\n",
    "    shortcut = block_input\n",
    "\n",
    "    # Define the residual block output and apply ReLU\n",
    "    block_restore = tfl.Add() ([block_restore, shortcut])\n",
    "    block_output = tfl.Activation(\"relu\") (block_restore)\n",
    "\n",
    "    # Return the residual block output\n",
    "    return block_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Defining the ResNet50 \"projection shortcut block\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_block(block_input, filters, strides=(2,2), stage=\"n\", block=\"m\"):\n",
    "    \"\"\"\n",
    "    Projection (convolutional) shortcut block implementation with bottleneck design from ResNet-50 architecture.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the block name with stage prefix\n",
    "    block_name = f\"proj_block_{str(stage)}_{str(block)}_\"\n",
    "    bn_name = f\"proj_bn_{str(stage)}_{str(block)}_\"\n",
    "\n",
    "    # Unpack the filters input\n",
    "    f1, f2, f3 = filters\n",
    "\n",
    "    # Define the destructing step of bottleneck design, apply BatchNorm and ReLU\n",
    "    block_destruct = tfl.Conv2D(filters=f1, kernel_size=(1,1), strides=strides, padding=\"valid\", kernel_initializer=\"he_normal\", name=block_name+ \"d\") (block_input)\n",
    "    block_destruct = tfl.BatchNormalization(name=bn_name+\"d\") (block_destruct)\n",
    "    block_destruct = tfl.Activation(\"relu\", name=block_name+\"act\"+\"_d\") (block_destruct)\n",
    "\n",
    "    # Define the feature extractor step of bottleneck design, apply BatchNorm and ReLU\n",
    "    block_neck = tfl.Conv2D(filters=f2, kernel_size=(3,3), strides=(1,1),  padding=\"same\", kernel_initializer=\"he_normal\", name=block_name+ \"n\") (block_destruct)\n",
    "    block_neck = tfl.BatchNormalization(name=bn_name+\"n\") (block_neck)\n",
    "    block_neck = tfl.Activation(\"relu\", name=block_name+\"act\"+\"_n\") (block_neck)\n",
    "\n",
    "    # Define the restoring step of bottleneck design, apply BatchNorm and ReLU\n",
    "    block_restore = tfl.Conv2D(filters=f3, kernel_size=(1,1), strides=(1,1), padding=\"valid\", kernel_initializer=\"he_normal\", name=block_name+ \"r\") (block_neck)\n",
    "    block_restore = tfl.BatchNormalization(name=bn_name+\"r\") (block_restore)\n",
    "\n",
    "    # Define shortcut connection\n",
    "    shortcut = tfl.Conv2D(filters=f3, kernel_size=(1,1), strides=strides, padding=\"valid\", name=block_name+\"sc\") (block_input)\n",
    "    shortcut = tfl.BatchNormalization() (shortcut)\n",
    "\n",
    "    # Define the residual block output and apply ReLU\n",
    "    block_restore = tfl.Add() ([block_restore, shortcut])\n",
    "    block_output = tfl.Activation(\"relu\", name=block_name+\"act\"+\"_o\") (block_restore)\n",
    "\n",
    "    # Return the residual block output\n",
    "    return block_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Defining the ResNet50 \"initial block\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_block(input_layer, filters=64, stage=\"1\", block=\"1\"):\n",
    "    \"\"\"\n",
    "    Initializer block of ResNet architecture that applies zero-padding, conv2d and max-pooling respectively. \n",
    "    \"\"\"\n",
    "\n",
    "    # Define the block name\n",
    "    block_name = f\"initial_{str(stage)}_{str(block)}_\"\n",
    "\n",
    "    # Apply initial zero-padding to preserve dims.\n",
    "    block_init = tfl.ZeroPadding2D(padding=(3,3)) (input_layer)\n",
    "\n",
    "    # Define the initial conv. block, apply BatchNorm and ReLU\n",
    "    block_init = tfl.Conv2D(filters=filters, kernel_size=(7,7), strides=(2,2), padding=\"valid\", kernel_initializer=\"he_normal\", name=block_name+\"conv\") (block_init)\n",
    "    block_init = tfl.BatchNormalization(name=block_name + \"bn\") (block_init) \n",
    "    block_init = tfl.Activation(\"relu\") (block_init)\n",
    "\n",
    "    # Apply max-pooling\n",
    "    block_init = tfl.MaxPool2D(pool_size=(3,3), strides=(2,2)) (block_init)\n",
    "\n",
    "    # Return initial block output\n",
    "    return block_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Defining the ResNet50 model architecture function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(224,224,3), output_classes_shape=10):\n",
    "\n",
    "    # Define the input layer object\n",
    "    layer_input = tf.keras.Input(input_shape)\n",
    "\n",
    "    # STAGE-1: INIT\n",
    "    block_init = initial_block(layer_input)\n",
    "\n",
    "    # STAGE-2: 3x Residual Block\n",
    "    stage2 = projection_block(block_init, (64,64,256), strides=(1,1), stage=2, block=1)\n",
    "    stage2 = identity_block(stage2, (64,64,256), stage=2, block=2)\n",
    "    stage2 = identity_block(stage2, (64,64,256), stage=2, block=3)\n",
    "\n",
    "    # STAGE-3: 4x Residual Block\n",
    "    stage3 = projection_block(stage2, (128,128,512), stage=3, block=1)\n",
    "    stage3 = identity_block(stage3, (128,128,512), stage=3, block=2)\n",
    "    stage3 = identity_block(stage3, (128,128,512), stage=3, block=3)\n",
    "    stage3 = identity_block(stage3, (128,128,512), stage=3, block=4)\n",
    "\n",
    "    # STAGE-4: 6x Residual Block\n",
    "    stage4 = projection_block(stage3, (256,256,1024), stage=4, block=1)\n",
    "    stage4 = identity_block(stage4, (256,256,1024), stage=4, block=2)\n",
    "    stage4 = identity_block(stage4, (256,256,1024), stage=4, block=3)\n",
    "    stage4 = identity_block(stage4, (256,256,1024), stage=4, block=4)\n",
    "    stage4 = identity_block(stage4, (256,256,1024), stage=4, block=5)\n",
    "    stage4 = identity_block(stage4, (256,256,1024), stage=4, block=6)\n",
    "\n",
    "    # STAGE-5: 3x Residual Block\n",
    "    stage5 = projection_block(stage4, (512,512,2048), stage=5, block=1)\n",
    "    stage5 = identity_block(stage5, (512,512,2048), stage=5, block=2)\n",
    "    stage5 = identity_block(stage5, (512,512,2048), stage=5, block=3)\n",
    "\n",
    "    # OUTRO\n",
    "    stage6 = tfl.AveragePooling2D(pool_size=(7,7)) (stage5)\n",
    "    stage6 = tfl.Flatten() (stage6)\n",
    "    layer_output = tfl.Dense(units=output_classes_shape, activation=\"softmax\") (stage6)\n",
    "\n",
    "    # Definition of model object\n",
    "    model = tf.keras.Model(inputs=layer_input, outputs=layer_output)\n",
    "\n",
    "    # Return the model object\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Creating a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining input shape\n",
    "input_shape = tuple([int(i) for i in image_dataset.element_spec[0].shape.__repr__()[-13:-2].split(\", \")])\n",
    "print(\"Input shape:\",input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining output shape\n",
    "output_classes_shape = len(classes_list)\n",
    "print(\"Output shape:\", output_classes_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50Model = ResNet50(input_shape, output_classes_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50Model.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
    "                    loss= tf.keras.losses.CategoricalCrossentropy(),\n",
    "                    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Printing the model architecture summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint path\n",
    "path_checkpoint = path_root + \"checkpoints/resnet50_model_{epoch:02d}-{val_accuracy:.2f}\"\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "callback_model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=path_checkpoint,\n",
    "    save_weights_only=False,\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_freq=\"epoch\" )\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "callback_early_stopping  = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = resnet50Model.fit(\n",
    "    x=dataset_train,\n",
    "    epochs=10,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[\n",
    "        callback_model_checkpoint,\n",
    "        callback_early_stopping\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_loss = history.history[\"loss\"]\n",
    "history_accuracy = history.history[\"accuracy\"]\n",
    "history_val_loss = history.history[\"val_loss\"]\n",
    "history_val_accuracy = history.history[\"val_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, (ax11, ax12)  = plt.subplots(1, 2, figsize=(16,8))\n",
    "ax11.plot(history_loss, label=\"train\")\n",
    "ax11.plot(history_val_loss, label=\"validation\")\n",
    "ax11.set_title(\"model loss\")\n",
    "ax11.legend(loc=\"upper right\")\n",
    "ax11.grid()\n",
    "\n",
    "ax12.plot(history_accuracy, label=\"train\")\n",
    "ax12.plot(history_val_accuracy, label=\"validation\")\n",
    "ax12.set_title(\"model accuracy\")\n",
    "ax12.legend(loc=\"upper right\")\n",
    "ax12.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Testing (Evaluating) the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history = resnet50Model.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test loss:\", test_history[0])\n",
    "print(\"Test accuracy:\", test_history[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ResNet50\"\n",
    "\n",
    "model_path = path_root + \"models/\" + model_name\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50Model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7- Reload Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ResNet50\"\n",
    "\n",
    "model_path = path_root + \"models/\" + model_name\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reloaded = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8- Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1- User Image Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an user image to evaluate its content by using the trained model\n",
    "1) Definition of untility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user_image(path):\n",
    "\n",
    "    # Lazy-load the image with PIL\n",
    "    image_user = Image.open(path)\n",
    "    plt.imshow(image_user)\n",
    "    # Resize the image\n",
    "    image_user = tf.image.resize(image_user, [224,224])\n",
    "    # Rescale the image\n",
    "    image_user = tfl.Rescaling(scale=1./255) (image_user)\n",
    "    # Add batch axis\n",
    "    image_user = image_user[tf.newaxis,:]\n",
    "    print(\"User Image Shape:\", image_user.shape)\n",
    "\n",
    "    # Return the image\n",
    "    return image_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred_result(result, classes):\n",
    "    print(f\"{'Predictions':<30}Confidences\")\n",
    "    result_top5 = []\n",
    "    result = list(result[0])\n",
    "\n",
    "    zipped_results = list(zip(result, list(enumerate(classes))))\n",
    "    sorted_zipped_results = sorted(zipped_results, reverse=True)\n",
    "    sorted_results_top5 = sorted_zipped_results[:5]\n",
    "    \n",
    "    for i, result in enumerate(sorted_results_top5):\n",
    "\n",
    "        result_index = result[1][0]\n",
    "        predicted_class = result[1][1]\n",
    "        confidence = result[0]\n",
    "        print(f\"{i+1} - {predicted_class:<25} - {confidence*100:.5f} %\")\n",
    "        result_top5.append([result_index, predicted_class, confidence])\n",
    "\n",
    "    # return top-5 prediction list\n",
    "    return result_top5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Define the user image path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_user_image = path_root + \"user_images/snowberg/snowberg_3.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Load the user image and preprocess within the 'load_user_image' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_user = load_user_image(path_user_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Make prediction by using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_user_image = model_reloaded.predict(image_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Print the top-5 prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_top5 = print_pred_result(result_user_image, classes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2- User Set Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define the user image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_user_set = path_root + \"user_images\"\n",
    "path_user_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get the user dataset with filenames format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_user_set = tf.data.Dataset.list_files(str(path_user_set+\"/*/*\"), shuffle=True)\n",
    "\n",
    "# Examples\n",
    "for ex in list_user_set.take(5):\n",
    "    # Print modified-for-readiblity version of samples \n",
    "    print(ex.numpy().split(b\"/\")[-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Apply \"convert_path_to_image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_user_set = list_user_set.map(convert_path_to_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Apply \"one_hot_encoder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_user_set = image_user_set.map(lambda image,label: one_hot_encoder(image, label, classes_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Apply \"resize_image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, label, size=[224,224]):\n",
    "    # Resizing\n",
    "    image = tf.image.resize(image, size)\n",
    "    # Type casting to uint8 from float32\n",
    "    image = tf.cast(image, dtype=tf.uint8) \n",
    "\n",
    "    # Return image and label\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_user_set = image_user_set.map(resize_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Apply \"rescaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_user_set = image_user_set.map(rescaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_test(image_user_set, one_hot_label=True, classes=classes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Apply mini-batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_user_set = image_user_set.batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_user_set.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_user_set = model_reloaded.evaluate(image_user_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Set Top-1 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User set loss:\", results_user_set[0])\n",
    "print(\"User set accuracy:\", results_user_set[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eeb7e7f481380f66e524d8ee2e79795c015a1143179697565aac94a9579f857a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dl_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
